# Offline AI Agent Configuration File

# Application Settings
app:
  name: "Offline AI Agent"
  version: "1.0.0"
  debug: false
  log_level: "INFO"
  max_workers: 4

# Model Configuration
model:
  # Primary language model
  llm:
    provider: "ollama"  # Options: ollama, huggingface, local
    model_name: "llama2:7b"  # For Ollama
    # model_name: "microsoft/DialoGPT-medium"  # For HuggingFace
    temperature: 0.7
    max_tokens: 2048
    context_window: 4096
    
  # Embedding model for vector search
  embedding:
    model_name: "sentence-transformers/all-MiniLM-L6-v2"
    dimension: 384
    batch_size: 32
    device: "cpu"  # Options: cpu, cuda

# Vector Database Configuration
vector_db:
  provider: "chromadb"  # Options: chromadb, faiss
  persist_directory: "./data/vector_store"
  collection_name: "documents"
  similarity_metric: "cosine"  # Options: cosine, l2, ip
  
# Document Processing
document_processing:
  supported_formats:
    - "pdf"
    - "txt"
    - "md"
    - "docx"
    - "html"
  
  chunking:
    strategy: "recursive"  # Options: fixed, recursive, semantic
    chunk_size: 1000
    chunk_overlap: 200
    separators: ["\n\n", "\n", " ", ""]
  
  # OCR settings for scanned documents
  ocr:
    enabled: false
    engine: "tesseract"  # Options: tesseract, easyocr
    languages: ["en", "ar"]

# RAG (Retrieval-Augmented Generation) Settings
rag:
  retrieval:
    top_k: 5  # Number of documents to retrieve
    score_threshold: 0.5  # Minimum similarity score
    rerank: true
    
  generation:
    system_prompt: |
      You are a helpful AI assistant that answers questions based on the provided context.
      Use only the information from the context to answer questions.
      If the context doesn't contain enough information, say so clearly.
      Provide accurate and concise answers in both English and Arabic when appropriate.
    
    max_context_length: 3000
    include_sources: true

# API Configuration
api:
  enabled: true
  host: "0.0.0.0"
  port: 8000
  cors_origins: ["*"]
  rate_limit:
    requests_per_minute: 60
    burst_size: 10

# File Storage
storage:
  documents_path: "./data/documents"
  uploads_path: "./data/uploads"
  temp_path: "./data/temp"
  max_file_size: "50MB"
  cleanup_temp_files: true
  retention_days: 30

# Security
security:
  api_key_required: false
  allowed_file_types:
    - "pdf"
    - "txt"
    - "md" 
    - "docx"
    - "html"
  
  content_filtering:
    enabled: true
    block_personal_info: true
    max_query_length: 1000

# Monitoring and Logging
monitoring:
  metrics_enabled: true
  health_check_endpoint: "/health"
  
  logging:
    file_path: "./logs/app.log"
    max_size: "100MB"
    backup_count: 5
    format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

# Caching
cache:
  enabled: true
  backend: "memory"  # Options: memory, redis
  ttl_seconds: 3600  # 1 hour
  max_size: 1000

# Language Support
languages:
  primary: "en"
  supported: ["en", "ar"]
  detection:
    enabled: true
    confidence_threshold: 0.8

# Advanced Features
features:
  conversation_memory: true
  context_preservation: true
  multi_turn_dialogue: true
  document_summarization: true
  keyword_extraction: true
  
# Development Settings
development:
  reload: true
  profiling: false
  test_mode: false
  mock_responses: false
